{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating predictions for 5 models and exporting\n",
    "\n",
    "**Methods:**\n",
    ">1. Load data and create subset\n",
    ">2. Generate SVM-poly model and export\n",
    ">3. Generate GBM model\n",
    ">4. Generate AdaBoost Model\n",
    ">5. Generate Logistic regression model\n",
    ">6. Generate kNN Model\n",
    ">7. Load all models, concat, and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.svm as skl_svm\n",
    "import sklearn.cross_validation as skl_cv\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "\n",
    "base_path = '/home/lundi/Python/MNIST/'\n",
    "sys.path.append(base_path + '/libraries/')\n",
    "\n",
    "import time\n",
    "\n",
    "import sklearn.linear_model as skl_lm\n",
    "import sklearn.ensemble as skl_ensemble\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "import MNIST_data_processor as mdp\n",
    "import MNIST_model_functions as mmf\n",
    "\n",
    "MNIST_data_processor = mdp.MNIST_data_processor()\n",
    "MNIST_model_functions = mmf.MNIST_model_functions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data and create subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = MNIST_data_processor.load_subset_data(train_test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pixel0      int64\n",
       "pixel1      int64\n",
       "pixel2      int64\n",
       "pixel3      int64\n",
       "pixel4      int64\n",
       "pixel5      int64\n",
       "pixel6      int64\n",
       "pixel7      int64\n",
       "pixel8      int64\n",
       "pixel9      int64\n",
       "pixel10     int64\n",
       "pixel11     int64\n",
       "pixel12     int64\n",
       "pixel13     int64\n",
       "pixel14     int64\n",
       "pixel15     int64\n",
       "pixel16     int64\n",
       "pixel17     int64\n",
       "pixel18     int64\n",
       "pixel19     int64\n",
       "pixel20     int64\n",
       "pixel21     int64\n",
       "pixel22     int64\n",
       "pixel23     int64\n",
       "pixel24     int64\n",
       "pixel25     int64\n",
       "pixel26     int64\n",
       "pixel27     int64\n",
       "pixel28     int64\n",
       "pixel29     int64\n",
       "            ...  \n",
       "pixel754    int64\n",
       "pixel755    int64\n",
       "pixel756    int64\n",
       "pixel757    int64\n",
       "pixel758    int64\n",
       "pixel759    int64\n",
       "pixel760    int64\n",
       "pixel761    int64\n",
       "pixel762    int64\n",
       "pixel763    int64\n",
       "pixel764    int64\n",
       "pixel765    int64\n",
       "pixel766    int64\n",
       "pixel767    int64\n",
       "pixel768    int64\n",
       "pixel769    int64\n",
       "pixel770    int64\n",
       "pixel771    int64\n",
       "pixel772    int64\n",
       "pixel773    int64\n",
       "pixel774    int64\n",
       "pixel775    int64\n",
       "pixel776    int64\n",
       "pixel777    int64\n",
       "pixel778    int64\n",
       "pixel779    int64\n",
       "pixel780    int64\n",
       "pixel781    int64\n",
       "pixel782    int64\n",
       "pixel783    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate SVM-poly model and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time:  1.46004854838  mins\n"
     ]
    }
   ],
   "source": [
    "svc_poly_clf = skl_svm.SVC(\n",
    "    C=2.8e-5, \n",
    "    degree=2, \n",
    "    gamma='auto', \n",
    "    kernel='poly', \n",
    "    tol=0.001,\n",
    "    probability=True\n",
    ")\n",
    "start_time = time.time()\n",
    "\n",
    "svc_poly_results = MNIST_model_functions.cross_val_predict_proba(\n",
    "                        estimator = svc_poly_clf, \n",
    "                        X = X, y = y, \n",
    "                        cv=5, \n",
    "                        model_name = 'SVC_Poly'\n",
    "                    )\n",
    "svc_poly_results.to_csv(base_path + '/data/prediction_results/2016.11.7-svc_results.csv')\n",
    "end_time = time.time()\n",
    "\n",
    "print 'Elapsed Time: ', (end_time - start_time) / 60.0, ' mins'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate GBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1        8993.6978           26.90m\n",
      "         2        8794.3160           26.95m\n",
      "         3        8607.8377           26.94m\n",
      "         4        8432.9118           26.97m\n",
      "         5        8267.6491           26.94m\n",
      "         6        8111.1804           26.98m\n",
      "         7        7963.6818           27.01m\n",
      "         8        7822.7756           27.06m\n",
      "         9        7686.8483           27.09m\n",
      "        10        7556.8896           27.14m\n",
      "        20        6473.7756           27.55m\n",
      "        30        5661.8096           27.60m\n",
      "        40        5007.4252           27.77m\n",
      "        50        4466.0110           27.68m\n",
      "        60        4009.3726           27.60m\n",
      "        70        3622.3111           27.76m\n",
      "        80        3277.9020           28.03m\n",
      "        90        2968.2557           28.05m\n",
      "       100        2695.6103           28.23m\n",
      "       200        1196.9376           27.16m\n",
      "       300         643.1813           25.28m\n",
      "       400         384.0159           23.24m\n",
      "       500         248.7055           21.01m\n",
      "       600         167.5364           18.61m\n",
      "       700         116.1363           16.33m\n",
      "       800          82.1528           14.12m\n",
      "       900          58.9819           11.99m\n",
      "      1000          42.9665            9.91m\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1        8985.2794           27.01m\n",
      "         2        8775.7408           26.85m\n",
      "         3        8581.0139           26.87m\n",
      "         4        8398.6361           26.83m\n",
      "         5        8225.1608           26.87m\n",
      "         6        8063.5665           26.84m\n",
      "         7        7909.2586           26.86m\n",
      "         8        7761.4443           26.95m\n",
      "         9        7623.6194           26.89m\n",
      "        10        7489.3704           26.96m\n",
      "        20        6393.4842           26.97m\n",
      "        30        5586.1357           26.83m\n",
      "        40        4936.1828           26.75m\n",
      "        50        4392.5419           26.62m\n",
      "        60        3940.7285           26.50m\n",
      "        70        3554.9578           26.46m\n",
      "        80        3226.5461           26.41m\n",
      "        90        2935.1220           26.38m\n",
      "       100        2685.2456           26.34m\n",
      "       200        1205.1567           25.72m\n",
      "       300         663.6261           23.74m\n",
      "       400         412.0032           21.61m\n",
      "       500         268.9040           19.55m\n",
      "       600         181.2698           17.52m\n",
      "       700         126.2850           15.49m\n",
      "       800          89.5601           13.51m\n",
      "       900          64.0410           11.55m\n",
      "      1000          46.8732            9.58m\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1        8986.8570           26.91m\n",
      "         2        8779.8944           26.89m\n",
      "         3        8586.7154           26.90m\n",
      "         4        8404.3956           26.89m\n",
      "         5        8232.8764           26.91m\n",
      "         6        8071.0260           26.89m\n",
      "         7        7917.7668           26.93m\n",
      "         8        7772.2800           26.92m\n",
      "         9        7631.7890           26.90m\n",
      "        10        7498.7804           26.89m\n",
      "        20        6399.9555           26.76m\n",
      "        30        5564.8100           26.74m\n",
      "        40        4915.4899           26.75m\n",
      "        50        4382.6500           26.72m\n",
      "        60        3936.5501           26.69m\n",
      "        70        3559.0256           26.59m\n",
      "        80        3228.2814           26.54m\n",
      "        90        2944.8552           26.46m\n",
      "       100        2684.7522           26.40m\n",
      "       200        1198.1421           25.67m\n",
      "       300         657.7041           23.80m\n",
      "       400         403.4654           21.72m\n",
      "       500         267.6328           19.60m\n",
      "       600         182.0017           17.55m\n",
      "       700         125.5561           15.55m\n",
      "       800          88.0691           13.55m\n",
      "       900          63.0534           11.56m\n",
      "      1000          45.5613            9.60m\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1        8986.9416           27.19m\n",
      "         2        8779.1409           27.29m\n",
      "         3        8586.2643           27.29m\n",
      "         4        8405.2977           27.28m\n",
      "         5        8234.1328           27.28m\n",
      "         6        8071.4271           27.28m\n",
      "         7        7917.9331           27.27m\n",
      "         8        7771.5850           27.27m\n",
      "         9        7631.9192           27.25m\n",
      "        10        7497.5772           27.25m\n",
      "        20        6402.1602           27.09m\n",
      "        30        5587.6689           26.94m\n",
      "        40        4944.9880           26.75m\n",
      "        50        4406.9349           26.66m\n",
      "        60        3946.7675           26.62m\n",
      "        70        3560.2369           26.51m\n",
      "        80        3224.7718           26.41m\n",
      "        90        2927.4186           26.40m\n",
      "       100        2656.3867           26.46m\n",
      "       200        1182.1352           25.77m\n",
      "       300         646.3026           23.95m\n",
      "       400         386.8501           21.89m\n",
      "       500         249.9249           19.76m\n",
      "       600         167.6697           17.72m\n",
      "       700         115.2947           15.68m\n",
      "       800          81.2063           13.63m\n",
      "       900          57.7795           11.63m\n",
      "      1000          41.4888            9.64m\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1        8992.5078           27.14m\n",
      "         2        8784.9232           27.30m\n",
      "         3        8591.3035           27.33m\n",
      "         4        8409.5892           27.33m\n",
      "         5        8239.9461           27.34m\n",
      "         6        8077.3424           27.28m\n",
      "         7        7923.3978           27.31m\n",
      "         8        7772.7650           27.27m\n",
      "         9        7631.5058           27.21m\n",
      "        10        7496.3671           27.23m\n",
      "        20        6392.7679           26.96m\n",
      "        30        5579.0857           26.78m\n",
      "        40        4930.0234           26.62m\n",
      "        50        4401.6683           26.48m\n",
      "        60        3957.1798           26.35m\n",
      "        70        3567.6244           26.29m\n",
      "        80        3234.3665           26.31m\n",
      "        90        2949.4789           26.28m\n",
      "       100        2693.2204           26.26m\n",
      "       200        1207.4342           25.59m\n",
      "       300         663.6262           23.74m\n",
      "       400         412.2307           21.61m\n",
      "       500         269.0133           19.53m\n",
      "       600         183.2451           17.43m\n",
      "       700         128.5923           15.39m\n",
      "       800          91.6176           13.38m\n",
      "       900          65.7530           11.43m\n",
      "      1000          47.6431            9.48m\n",
      "Elapsed Time:  141.232557968  mins\n"
     ]
    }
   ],
   "source": [
    "gbm_clf = skl_ensemble.GradientBoostingClassifier(verbose=True, n_estimators=1500, learning_rate=0.01, max_leaf_nodes=50)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "gbm_results = MNIST_model_functions.cross_val_predict_proba(\n",
    "                        estimator = gbm_clf, \n",
    "                        X = X, y = y, \n",
    "                        cv=5, \n",
    "                        model_name = 'GBM'\n",
    "                    )\n",
    "gbm_results.to_csv(base_path + '/data/prediction_results/2016.11.7-gbm_results.csv')\n",
    "end_time = time.time()\n",
    "\n",
    "print 'Elapsed Time: ', (end_time - start_time) / 60.0, ' mins'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate RF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_clf = skl_ensemble.RandomForestClassifier(n_estimators = 1500, criterion = 'entropy', max_depth = 25)\n",
    "\n",
    "rf_results = MNIST_model_functions.cross_val_predict_proba(rf_clf, X = X, y = y, cv = 5, model_name = 'RF')\n",
    "rf_results.to_csv(base_path + '/data/prediction_results/2016.11.7-rf_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr_clf = skl_lm.LogisticRegression(penalty = 'l2', C = 1.4e-6)\n",
    "\n",
    "lr_results = MNIST_model_functions.cross_val_predict_proba(lr_clf, X = X, y = y, cv = 5, model_name = 'LR')\n",
    "lr_results.to_csv(base_path + '/data/prediction_results/2016.11.7-lr_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generate kNN Model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
