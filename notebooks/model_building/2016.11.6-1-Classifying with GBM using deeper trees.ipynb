{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying with GBM using deeper trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.svm as skl_svm\n",
    "import sklearn.cross_validation as skl_cv\n",
    "import sklearn.ensemble as skl_ensemble\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import time\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "digit_data = pd.read_csv('Data/train.csv')\n",
    "X = digit_data.ix[:,1:digit_data.shape[1]]\n",
    "y = digit_data['label']\n",
    "X_subset = X.ix[0:5000,:]\n",
    "y_subset = y.ix[0:5000]\n",
    "\n",
    "X_train, X_test, y_train, y_test = skl_cv.train_test_split(X_subset, y_subset, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbm_clf = skl_ensemble.GradientBoostingClassifier(verbose=True, n_estimators=600, learning_rate=0.1, max_leaf_nodes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1        7146.9828           11.04m\n",
      "         2        6015.0066           11.09m\n",
      "         3        5219.7225           11.15m\n",
      "         4        4629.6947           11.11m\n",
      "         5        4142.4426           11.04m\n",
      "         6        3720.7394           11.07m\n",
      "         7        3359.2531           11.12m\n",
      "         8        3049.2468           11.17m\n",
      "         9        2762.7042           11.24m\n",
      "        10        2523.1591           11.29m\n",
      "        20        1136.6834           11.59m\n",
      "        30         630.5898           11.46m\n",
      "        40         390.1343           11.20m\n",
      "        50         250.6399           10.95m\n",
      "        60         169.7409           10.68m\n",
      "        70         117.1191           10.44m\n",
      "        80          82.6114           10.22m\n",
      "        90          59.6453            9.96m\n",
      "       100          42.5923            9.73m\n",
      "       200           2.8789            6.99m\n",
      "       300           1.4560            3.83m\n",
      "       400           1.4339            1.93m\n",
      "       500           1.4339           46.53s\n",
      "       600           1.4339            0.00s\n",
      "Elapsed Time:  234.014218092  seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "gbm_clf.fit(X_train, y_train);\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print 'Elapsed Time: ', end_time - start_time, ' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93306693306693311"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(gbm_clf.predict(X_test) == y_test.values).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the GBM gets 93.3% accuracy using max_leaf_nodes=15, n_estimators=600, and the subset of data (n=4,000). Let's try going deeper and add more tress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1        7143.2101           42.62m\n",
      "         2        6010.3450           44.99m\n",
      "         3        5218.9431           45.02m\n",
      "         4        4624.0047           44.85m\n",
      "         5        4128.7856           45.21m\n",
      "         6        3716.1754           45.27m\n",
      "         7        3361.3323           44.92m\n",
      "         8        3036.5369           44.64m\n",
      "         9        2759.6336           44.53m\n",
      "        10        2512.1649           43.64m\n",
      "        20        1136.1035           34.25m\n",
      "        30         629.0533           31.18m\n",
      "        40         381.9679           29.18m\n",
      "        50         245.4960           27.62m\n",
      "        60         164.3440           26.78m\n",
      "        70         114.0362           25.77m\n",
      "        80          82.3250           25.15m\n",
      "        90          59.6250           25.05m\n",
      "       100          43.6793           25.01m\n",
      "       200           2.8258           19.36m\n",
      "       300           1.4489           12.60m\n",
      "       400           1.4329            8.46m\n",
      "       500           1.4329            5.95m\n",
      "       600           1.4329            4.28m\n",
      "       700           1.4329            3.07m\n",
      "       800           1.4329            2.16m\n",
      "       900           1.4329            1.45m\n",
      "      1000           1.4329           52.44s\n",
      "Elapsed Time:  265.109665871  seconds\n"
     ]
    }
   ],
   "source": [
    "gbm_clf = skl_ensemble.GradientBoostingClassifier(verbose=True, n_estimators=1200, learning_rate=0.1, max_leaf_nodes=25)\n",
    "start_time = time.time()\n",
    "\n",
    "gbm_clf.fit(X_train, y_train);\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print 'Elapsed Time: ', end_time - start_time, ' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93906093906093902"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(gbm_clf.predict(X_test) == y_test.values).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slight improvement to 93.9% up from 93.3%. This isn't quite what I was hoping for. I will now reduce the learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1        8988.4191           22.54m\n",
      "         2        8785.9181           22.34m\n",
      "         3        8597.2597           22.14m\n",
      "         4        8414.8648           22.22m\n",
      "         5        8246.2158           22.30m\n",
      "         6        8083.5764           22.47m\n",
      "         7        7930.9643           22.50m\n",
      "         8        7785.5677           22.42m\n",
      "         9        7647.4831           22.34m\n",
      "        10        7511.9254           22.28m\n",
      "        20        6410.4709           22.02m\n",
      "        30        5579.0527           21.91m\n",
      "        40        4928.7215           22.05m\n",
      "        50        4389.0527           22.32m\n",
      "        60        3943.2290           22.52m\n",
      "        70        3561.2868           22.23m\n",
      "        80        3214.8356           22.17m\n",
      "        90        2920.3107           22.05m\n",
      "       100        2663.8260           21.89m\n",
      "       200        1199.1041           20.38m\n",
      "       300         655.6966           18.37m\n",
      "       400         399.9558           16.22m\n",
      "       500         257.5591           17.78m\n",
      "       600         173.8965           20.42m\n",
      "       700         119.1548           16.47m\n",
      "       800          83.6389           12.72m\n",
      "       900          59.6769            9.17m\n",
      "      1000          43.1941            5.90m\n",
      "Elapsed Time:  2031.03454494  seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.93106893106893107"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_clf = skl_ensemble.GradientBoostingClassifier(verbose=True, n_estimators=1200, learning_rate=0.01, max_leaf_nodes=25)\n",
    "start_time = time.time()\n",
    "\n",
    "gbm_clf.fit(X_train, y_train);\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print 'Elapsed Time: ', end_time - start_time, ' seconds'\n",
    "\n",
    "(gbm_clf.predict(X_test) == y_test.values).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1        8988.4189           37.28m\n",
      "         2        8785.9180           37.11m\n",
      "         3        8597.2597           36.99m\n",
      "         4        8414.8647           37.75m\n",
      "         5        8246.2157           37.56m\n",
      "         6        8083.5764           37.46m\n",
      "         7        7930.9643           37.43m\n",
      "         8        7785.5676           37.52m\n",
      "         9        7647.4830           37.42m\n",
      "        10        7511.9254           37.35m\n",
      "        20        6410.4709           37.22m\n",
      "        30        5579.0527           37.21m\n",
      "        40        4928.7215           37.08m\n",
      "        50        4389.0527           36.88m\n",
      "        60        3943.2289           36.67m\n",
      "        70        3561.2868           36.55m\n",
      "        80        3214.8356           36.62m\n",
      "        90        2920.3107           36.68m\n",
      "       100        2663.8260           36.73m\n",
      "       200        1199.1041           36.45m\n",
      "       300         655.6966           34.57m\n",
      "       400         399.9558           32.29m\n",
      "       500         257.5591           30.06m\n",
      "       600         173.8965           27.90m\n",
      "       700         119.1548           25.78m\n",
      "       800          83.6389           23.68m\n",
      "       900          59.6769           21.61m\n",
      "      1000          43.1338           19.55m\n",
      "      2000           2.7932            0.00s\n",
      "Elapsed Time:  2104.78086185  seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.93706293706293708"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_clf = skl_ensemble.GradientBoostingClassifier(verbose=True, n_estimators=2000, learning_rate=0.01, max_leaf_nodes=75)\n",
    "start_time = time.time()\n",
    "\n",
    "gbm_clf.fit(X_train, y_train);\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print 'Elapsed Time: ', end_time - start_time, ' seconds'\n",
    "\n",
    "(gbm_clf.predict(X_test) == y_test.values).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like gradient boosting hits a wall near ~94%. I will investigate which numbers it gets wrong:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
