{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating predictions for 5 models and exporting\n",
    "\n",
    "**Methods:**\n",
    ">1. Load data and create subset\n",
    ">2. Generate SVM-poly model and export\n",
    ">3. Generate GBM model\n",
    ">4. Generate AdaBoost Model\n",
    ">5. Generate Logistic regression model\n",
    ">6. Generate kNN Model\n",
    ">7. Load all models, concat, and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.svm as skl_svm\n",
    "import sklearn.cross_validation as skl_cv\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "\n",
    "base_path = '/home/lundi/Python/MNIST/'\n",
    "sys.path.append(base_path + '/libraries/')\n",
    "\n",
    "import time\n",
    "\n",
    "import sklearn.linear_model as skl_lm\n",
    "import sklearn.ensemble as skl_ensemble\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "import MNIST_data_processor as mdp\n",
    "import MNIST_model_functions as mmf\n",
    "\n",
    "MNIST_data_processor = mdp.MNIST_data_processor()\n",
    "MNIST_model_functions = mmf.MNIST_model_functions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data and create subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = MNIST_data_processor.load_full_data(train_test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate SVM-poly model and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time:  53.5365842183  mins\n"
     ]
    }
   ],
   "source": [
    "svc_poly_clf = skl_svm.SVC(\n",
    "    C=2.8e-5, \n",
    "    degree=2, \n",
    "    gamma='auto', \n",
    "    kernel='poly', \n",
    "    tol=0.001,\n",
    "    probability=True\n",
    ")\n",
    "start_time = time.time()\n",
    "\n",
    "svc_poly_results = MNIST_model_functions.cross_val_predict_proba(\n",
    "                        estimator = svc_poly_clf, \n",
    "                        X = X, y = y, \n",
    "                        cv=5, \n",
    "                        model_name = 'SVC_Poly'\n",
    "                    )\n",
    "svc_poly_results.to_csv(base_path + '/data/prediction_results/2016.11.7-svc_results.csv')\n",
    "end_time = time.time()\n",
    "\n",
    "print 'Elapsed Time: ', (end_time - start_time) / 60.0, ' mins'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate GBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1       75643.7433          275.14m\n",
      "         2       74051.2971          267.62m\n",
      "         3       72543.2483          267.39m\n",
      "         4       71128.0655          267.59m\n",
      "         5       69803.7753          269.41m\n",
      "         6       68534.5349          267.77m\n",
      "         7       67330.6865          267.33m\n",
      "         8       66182.2154          265.83m\n",
      "         9       65083.4920          265.33m\n",
      "        10       64050.8950          265.18m\n",
      "        20       55474.3252          256.52m\n",
      "        30       49017.6927          254.11m\n",
      "        40       43768.2087          251.76m\n",
      "        50       39454.9186          250.07m\n",
      "        60       35731.2641          250.97m\n",
      "        70       32543.0560          252.21m\n",
      "        80       29802.9301          252.05m\n",
      "        90       27432.2246          251.18m\n",
      "       100       25392.3966          250.08m\n",
      "       200       13536.0581          239.40m\n",
      "       300        9000.1539          221.41m\n",
      "       400        6628.9676          202.34m\n",
      "       500        5189.3495          183.12m\n",
      "       600        4231.0432          163.89m\n",
      "       700        3516.1995          144.88m\n",
      "       800        2967.2361          126.06m\n",
      "       900        2542.3914          107.22m\n",
      "      1000        2203.9517           88.71m\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1       75626.4806          252.34m\n",
      "         2       74012.9783          251.35m\n",
      "         3       72507.0627          251.06m\n",
      "         4       71100.6448          250.53m\n",
      "         5       69768.8503          251.34m\n",
      "         6       68514.3463          250.86m\n",
      "         7       67316.5196          251.02m\n",
      "         8       66176.4548          251.25m\n",
      "         9       65078.3167          250.95m\n",
      "        10       64029.7948          251.00m\n",
      "        20       55336.0415          249.54m\n",
      "        30       48812.5529          248.31m\n",
      "        40       43707.6198          246.76m\n",
      "        50       39406.1831          245.72m\n",
      "        60       35727.2144          245.62m\n",
      "        70       32548.4283          245.79m\n",
      "        80       29783.6063          245.78m\n",
      "        90       27419.3127          245.61m\n",
      "       100       25363.6970          245.18m\n",
      "       200       13537.4251          236.68m\n",
      "       300        8958.2885          219.49m\n",
      "       400        6611.2869          200.81m\n",
      "       500        5192.8235          181.57m\n",
      "       600        4226.8928          162.45m\n",
      "       700        3515.3627          143.54m\n",
      "       800        2970.1474          124.83m\n",
      "       900        2552.2549          106.26m\n",
      "      1000        2200.8014           88.02m\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1       75631.6248          248.42m\n",
      "         2       74027.2407          248.39m\n",
      "         3       72542.0408          247.80m\n",
      "         4       71141.7329          247.73m\n",
      "         5       69822.1078          247.64m\n",
      "         6       68579.2521          247.32m\n",
      "         7       67390.9325          247.15m\n",
      "         8       66262.7989          247.45m\n",
      "         9       65185.6401          247.14m\n",
      "        10       64144.4673          247.36m\n",
      "        20       55500.6990          247.35m\n",
      "        30       48984.6978          247.25m\n",
      "        40       43873.8248          246.27m\n",
      "        50       39652.2519          245.27m\n",
      "        60       35997.6345          244.48m\n",
      "        70       32748.2518          245.41m\n",
      "        80       30005.5239          245.79m\n",
      "        90       27650.3899          245.61m\n",
      "       100       25587.6639          245.36m\n",
      "       200       13601.9767          237.36m\n",
      "       300        9005.1543          220.26m\n",
      "       400        6602.2562          201.92m\n",
      "       500        5184.3508          182.96m\n",
      "       600        4208.4653          163.74m\n",
      "       700        3494.9680          144.57m\n",
      "       800        2943.1938          125.76m\n",
      "       900        2518.5188          106.99m\n",
      "      1000        2163.3727           88.69m\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1       75626.8244          251.57m\n",
      "         2       74014.7041          251.43m\n",
      "         3       72510.3155          251.21m\n",
      "         4       71093.3185          251.96m\n",
      "         5       69764.2126          251.60m\n",
      "         6       68503.4506          251.85m\n",
      "         7       67299.8251          251.08m\n",
      "         8       66148.1734          250.91m\n",
      "         9       65056.4897          250.38m\n",
      "        10       64013.7153          250.56m\n",
      "        20       55270.6860          249.37m\n",
      "        30       48768.9598          248.54m\n",
      "        40       43731.5539          246.94m\n",
      "        50       39470.6841          246.02m\n",
      "        60       35752.0089          245.71m\n",
      "        70       32589.7674          245.14m\n",
      "        80       29853.9477          244.83m\n",
      "        90       27458.8386          244.66m\n",
      "       100       25381.8918          244.47m\n",
      "       200       13575.3218          235.60m\n",
      "       300        8979.1129          218.85m\n",
      "       400        6616.4528          200.22m\n",
      "       500        5202.0120          181.39m\n",
      "       600        4222.9976          162.80m\n",
      "       700        3514.1549          143.93m\n",
      "       800        2967.8134          125.19m\n",
      "       900        2546.4936          106.66m\n",
      "      1000        2196.2061           88.37m\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1       75630.2799          255.29m\n",
      "         2       74024.9130          255.20m\n",
      "         3       72529.6180          254.86m\n",
      "         4       71119.9857          254.70m\n",
      "         5       69787.1608          253.83m\n",
      "         6       68521.8505          252.67m\n",
      "         7       67329.9138          252.72m\n",
      "         8       66189.4071          251.93m\n",
      "         9       65098.7453          251.73m\n",
      "        10       64060.8738          251.43m\n",
      "        20       55363.1103          250.72m\n",
      "        30       48855.9159          250.29m\n",
      "        40       43699.6942          248.63m\n",
      "        50       39390.4899          247.33m\n",
      "        60       35671.1302          246.98m\n",
      "        70       32478.8915          246.96m\n",
      "        80       29723.0881          246.95m\n",
      "        90       27356.1829          246.66m\n",
      "       100       25289.8590          246.19m\n",
      "       200       13554.8937          238.30m\n",
      "       300        8985.7356          221.38m\n",
      "       400        6679.4585          202.37m\n",
      "       500        5270.2388          182.89m\n",
      "       600        4308.7690          163.52m\n",
      "       700        3602.3299          144.49m\n",
      "       800        3061.0550          125.65m\n",
      "       900        2628.1574          106.86m\n",
      "      1000        2271.7100           88.52m\n",
      "Elapsed Time:  1299.76701738  mins\n"
     ]
    }
   ],
   "source": [
    "gbm_clf = skl_ensemble.GradientBoostingClassifier(verbose=True, n_estimators=1500, learning_rate=0.01, max_leaf_nodes=50)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "gbm_results = MNIST_model_functions.cross_val_predict_proba(\n",
    "                        estimator = gbm_clf, \n",
    "                        X = X, y = y, \n",
    "                        cv=5, \n",
    "                        model_name = 'GBM'\n",
    "                    )\n",
    "gbm_results.to_csv(base_path + '/data/prediction_results/2016.11.7-gbm_results.csv')\n",
    "end_time = time.time()\n",
    "\n",
    "print 'Elapsed Time: ', (end_time - start_time) / 60.0, ' mins'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate RF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_clf = skl_ensemble.RandomForestClassifier(n_estimators = 1500, criterion = 'entropy', max_depth = 25)\n",
    "\n",
    "rf_results = MNIST_model_functions.cross_val_predict_proba(rf_clf, X = X, y = y, cv = 5, model_name = 'RF')\n",
    "rf_results.to_csv(base_path + '/data/prediction_results/2016.11.7-rf_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr_clf = skl_lm.LogisticRegression(penalty = 'l2', C = 1.4e-6)\n",
    "\n",
    "lr_results = MNIST_model_functions.cross_val_predict_proba(lr_clf, X = X, y = y, cv = 5, model_name = 'LR')\n",
    "lr_results.to_csv(base_path + '/data/prediction_results/2016.11.7-lr_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generate kNN Model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
