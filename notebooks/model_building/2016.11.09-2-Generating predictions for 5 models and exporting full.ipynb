{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating predictions for 5 models and exporting\n",
    "\n",
    "**Methods:**\n",
    ">1. Load data and create subset\n",
    ">2. Generate SVM-poly model and export\n",
    ">3. Generate GBM model\n",
    ">4. Generate AdaBoost Model\n",
    ">5. Generate Logistic regression model\n",
    ">6. Generate kNN Model\n",
    ">7. Load all models, concat, and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.svm as skl_svm\n",
    "import sklearn.cross_validation as skl_cv\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "\n",
    "base_path = '/home/lundi/Python/MNIST/'\n",
    "sys.path.append(base_path + '/libraries/')\n",
    "\n",
    "import time\n",
    "\n",
    "import sklearn.linear_model as skl_lm\n",
    "import sklearn.ensemble as skl_ensemble\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "import MNIST_data_processor as mdp\n",
    "import MNIST_model_functions as mmf\n",
    "\n",
    "MNIST_data_processor = mdp.MNIST_data_processor()\n",
    "MNIST_model_functions = mmf.MNIST_model_functions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data and create subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = MNIST_data_processor.load_subset_data(train_test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate SVM-poly model and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time:  1.42925251722  mins\n"
     ]
    }
   ],
   "source": [
    "svc_poly_clf = skl_svm.SVC(\n",
    "    C=2.8e-5, \n",
    "    degree=2, \n",
    "    gamma='auto', \n",
    "    kernel='poly', \n",
    "    tol=0.001,\n",
    "    probability=True\n",
    ")\n",
    "start_time = time.time()\n",
    "\n",
    "svc_poly_results = MNIST_model_functions.cross_val_predict_proba(\n",
    "                        estimator = svc_poly_clf, \n",
    "                        X = X, y = y, \n",
    "                        cv=5, \n",
    "                        model_name = 'SVC_Poly'\n",
    "                    )\n",
    "svc_poly_results.to_csv(base_path + '/data/prediction_results/2016.11.7-svc_results_subset.csv')\n",
    "end_time = time.time()\n",
    "\n",
    "print 'Elapsed Time: ', (end_time - start_time) / 60.0, ' mins'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate GBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1        8993.6978           26.41m\n",
      "         2        8794.3160           26.57m\n",
      "         3        8607.8377           26.53m\n",
      "         4        8432.9118           26.77m\n",
      "         5        8267.6491           26.69m\n",
      "         6        8111.1804           27.02m\n",
      "         7        7963.6818           27.22m\n",
      "         8        7822.7756           27.23m\n",
      "         9        7686.8483           27.21m\n",
      "        10        7556.8896           27.19m\n",
      "        20        6473.7756           26.86m\n",
      "        30        5661.8096           26.72m\n",
      "        40        5007.4252           26.69m\n",
      "        50        4466.0110           26.67m\n",
      "        60        4009.3726           26.60m\n",
      "        70        3622.3111           26.57m\n",
      "        80        3277.9020           26.57m\n",
      "        90        2968.2557           26.58m\n",
      "       100        2695.6103           26.62m\n",
      "       200        1196.9376           25.79m\n",
      "       300         643.1813           24.02m\n",
      "       400         384.0159           21.96m\n",
      "       500         248.7055           19.79m\n",
      "       600         167.5364           17.68m\n",
      "       700         116.1363           15.60m\n",
      "       800          82.1528           13.56m\n",
      "       900          58.9819           11.55m\n",
      "      1000          42.9665            9.58m\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1        8985.2794           26.80m\n",
      "         2        8775.7408           26.76m\n",
      "         3        8581.0139           26.84m\n",
      "         4        8398.6361           26.82m\n",
      "         5        8225.1608           26.88m\n",
      "         6        8063.5665           26.86m\n",
      "         7        7909.2586           26.87m\n",
      "         8        7761.4443           26.96m\n",
      "         9        7623.6194           26.91m\n",
      "        10        7489.3704           26.96m\n",
      "        20        6393.4842           26.93m\n",
      "        30        5586.1357           26.85m\n",
      "        40        4936.1828           26.79m\n",
      "        50        4392.5419           26.69m\n",
      "        60        3940.7285           26.58m\n",
      "        70        3554.9578           26.55m\n",
      "        80        3226.5461           26.49m\n",
      "        90        2935.1220           26.46m\n",
      "       100        2685.2456           26.42m\n",
      "       200        1205.1567           25.72m\n",
      "       300         663.6261           23.71m\n",
      "       400         412.0032           21.56m\n",
      "       500         268.9040           19.50m\n",
      "       600         181.2698           17.46m\n",
      "       700         126.2850           15.44m\n",
      "       800          89.5601           13.46m\n",
      "       900          64.0410           11.50m\n",
      "      1000          46.8732            9.55m\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1        8986.8565           26.92m\n",
      "         2        8779.8943           26.89m\n",
      "         3        8586.7154           26.90m\n",
      "         4        8404.3957           26.88m\n",
      "         5        8232.8767           26.88m\n",
      "         6        8071.0264           26.86m\n",
      "         7        7917.7673           26.97m\n",
      "         8        7772.2805           26.95m\n",
      "         9        7631.7896           26.91m\n",
      "        10        7498.7811           26.90m\n",
      "        20        6399.9566           26.80m\n",
      "        30        5564.8109           26.77m\n",
      "        40        4915.4906           26.79m\n",
      "        50        4382.6506           26.75m\n",
      "        60        3936.5504           26.70m\n",
      "        70        3559.0257           26.60m\n",
      "        80        3228.7121           26.52m\n",
      "        90        2944.9430           26.44m\n",
      "       100        2685.2190           26.36m\n",
      "       200        1197.0841           25.62m\n",
      "       300         657.4595           23.73m\n",
      "       400         403.6816           21.64m\n",
      "       500         267.3076           19.53m\n",
      "       600         181.9186           17.48m\n",
      "       700         126.4451           15.46m\n",
      "       800          89.0987           13.47m\n",
      "       900          63.5670           11.50m\n",
      "      1000          45.7029            9.56m\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1        8986.9416           27.19m\n",
      "         2        8779.1409           27.25m\n",
      "         3        8586.2643           27.26m\n",
      "         4        8405.2977           27.26m\n",
      "         5        8234.1328           27.28m\n",
      "         6        8071.4271           27.29m\n",
      "         7        7917.9331           27.29m\n",
      "         8        7771.5850           27.30m\n",
      "         9        7631.9192           27.28m\n",
      "        10        7497.5772           27.28m\n",
      "        20        6402.1602           27.11m\n",
      "        30        5587.6689           27.00m\n",
      "        40        4944.9880           26.83m\n",
      "        50        4406.9349           26.74m\n",
      "        60        3946.7675           26.71m\n",
      "        70        3560.2369           26.59m\n",
      "        80        3224.7718           26.48m\n",
      "        90        2927.4186           26.45m\n",
      "       100        2656.3867           26.49m\n",
      "       200        1182.1352           25.74m\n",
      "       300         646.3026           23.89m\n",
      "       400         386.8501           21.82m\n",
      "       500         249.9249           19.69m\n",
      "       600         167.6697           17.65m\n",
      "       700         115.2947           15.61m\n",
      "       800          81.2063           13.58m\n",
      "       900          57.7795           11.58m\n",
      "      1000          41.4888            9.60m\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1        8992.5080           27.11m\n",
      "         2        8784.9233           27.29m\n",
      "         3        8591.3035           27.36m\n",
      "         4        8409.5893           27.38m\n",
      "         5        8239.9462           27.39m\n",
      "         6        8077.3425           27.34m\n",
      "         7        7923.3979           27.37m\n",
      "         8        7772.7651           27.34m\n",
      "         9        7631.5058           27.28m\n",
      "        10        7496.3670           27.31m\n",
      "        20        6392.7679           27.09m\n",
      "        30        5579.0857           26.93m\n",
      "        40        4930.0234           26.79m\n",
      "        50        4401.6683           26.66m\n",
      "        60        3957.1799           26.52m\n",
      "        70        3567.6244           26.46m\n",
      "        80        3234.3666           26.48m\n",
      "        90        2949.4790           26.43m\n",
      "       100        2693.2205           26.40m\n",
      "       200        1207.4343           25.65m\n",
      "       300         663.6263           23.77m\n",
      "       400         412.2307           21.63m\n",
      "       500         269.0134           19.54m\n",
      "       600         183.2451           17.44m\n",
      "       700         128.5923           15.39m\n",
      "       800          91.6176           13.38m\n",
      "       900          65.7530           11.43m\n",
      "      1000          47.6431            9.49m\n",
      "Elapsed Time:  140.186027002  mins\n"
     ]
    }
   ],
   "source": [
    "gbm_clf = skl_ensemble.GradientBoostingClassifier(verbose=True, n_estimators=1500, learning_rate=0.01, max_leaf_nodes=50)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "gbm_results = MNIST_model_functions.cross_val_predict_proba(\n",
    "                        estimator = gbm_clf, \n",
    "                        X = X, y = y, \n",
    "                        cv=5, \n",
    "                        model_name = 'GBM'\n",
    "                    )\n",
    "gbm_results.to_csv(base_path + '/data/prediction_results/2016.11.7-gbm_results_subset.csv')\n",
    "end_time = time.time()\n",
    "\n",
    "print 'Elapsed Time: ', (end_time - start_time) / 60.0, ' mins'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate RF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_clf = skl_ensemble.RandomForestClassifier(n_estimators = 1500, criterion = 'entropy', max_depth = 25)\n",
    "\n",
    "rf_results = MNIST_model_functions.cross_val_predict_proba(rf_clf, X = X, y = y, cv = 5, model_name = 'RF')\n",
    "rf_results.to_csv(base_path + '/data/prediction_results/2016.11.7-rf_results_subset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr_clf = skl_lm.LogisticRegression(penalty = 'l2', C = 1.4e-6)\n",
    "\n",
    "lr_results = MNIST_model_functions.cross_val_predict_proba(lr_clf, X = X, y = y, cv = 5, model_name = 'LR')\n",
    "lr_results.to_csv(base_path + '/data/prediction_results/2016.11.7-lr_results_subset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generate kNN Model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
